{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Time-series\n",
    "\n",
    "Time-series are a key element when assessing solar resource data. In this section, we present several examples to learn how to deal with different formats in the data and few common tasks to prepare our time-series for later analysis, such as down and up-sampling data when we need different temporal resolution than that initially available or interpolating missing values in the data. \n",
    "\n",
    "The dataset used in the examples of this section is a customized dataset using solar radiation measurements from the Measurement and Instrumentation Data Center (MIDC) of the U.S. National Renewable Energy Laboratory (NREL). The station selected is located at the University of Nevada - Las Vegas (UNLV) and the data used are 1-minute GHI, DHI and DNI measurements for the year 2020 (Andreas and Stoffel, 2006).\n",
    "\n",
    "In this section, we cover:\n",
    "\n",
    "- [1 Time-series handling](#timeseries_handling)\n",
    "- [2 Down and up-sampling time-series data](#timeseries_downup_sampling)\n",
    "- [3 Interpolating time-series data](#timeseries_interpolation)\n",
    "- [4 Visualizating time-series data](#timeseries_visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series handling <a id='timeseries_handling'></a>\n",
    "Datasets often come in different formats depending on the source. Those formats sometimes cannot be used straightaway to build a time-series and may require additional processing steps before building the time-series. For example: \n",
    "- **What if date and time are in different columns?**\n",
    "- **What if the year, month, day and time are in separate columns?**\n",
    "- **How to the define the timestamp format for a particular dataset?**\n",
    "- **How to deal with timestamp issues, local vs. universal (UTC) time?**\n",
    "\n",
    "This subsection presents several examples to deal with different formats in which time-series data could come and shows how to build a time-series or *datetime series*, as known in Python, for later analysis. The processing steps to build time-series are based on [pandas library](https://pandas.pydata.org/).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pvlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our customized dataset\n",
    "In order to build the customized dataset for this section, we make use of the I/O tools of the Python library *pvlib* to retrieve the data from the UNLV station in the MIDC. Data from other stations from the MIDC can be also retrieved using this method by adapting the station ID in the query. The different station IDs are available in the [MIDC raw data page](https://midcdmz.nrel.gov/apps/data_api_doc.pl?_idtextlist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to rename certain variables from the raw data\n",
    "var_map = {'Global Horiz [W/m^2]': 'ghi',\n",
    "           'Direct Normal [W/m^2]': 'dni',\n",
    "           'Diffuse Horiz (calc) [W/m^2]': 'dhi',\n",
    "           'Year': 'year'}\n",
    "\n",
    "# Retrieving the raw data from the station \n",
    "df_ref = pvlib.iotools.read_midc_raw_data_from_nrel('UNLV',  # Station id\n",
    "                                                    pd.Timestamp('20200101'),  # Start date YYYYMMDD\n",
    "                                                    pd.Timestamp('20201231'),  # End date  YYYYMMDD\n",
    "                                                    variable_map=var_map)  # Variable Map\n",
    "# Let's have a look to the first 2 rows of the dataset\n",
    "df_ref.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look to the last 2 rows of the dataset\n",
    "df_ref.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is 1-minute resolution data with 21 variables related to meteorological and other relevant data: ambient temperature, wind speed, wind direction, global horizontal irradiance (GHI), direct normal irradiance (DNI), diffuse horizontal irradiance (DHI), zenith and azimuth angles, airmass, among other. \n",
    "\n",
    "For the examples in this section we will use GHI, DNI and DHI measurements and time-related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice desired variables out of the 21 variables provided in the raw data. \n",
    "df_ref = df_ref[['ghi', 'dni', 'dhi', 'year']]\n",
    "\n",
    "# Add multiple temporal data to the dataset\n",
    "df_ref['month'] = df_ref.index.month\n",
    "df_ref['day'] = df_ref.index.day\n",
    "df_ref['hour'] = df_ref.index.hour\n",
    "df_ref['minute'] = df_ref.index.minute\n",
    "df_ref['date'] = df_ref.index.strftime('%Y-%m-%d')\n",
    "df_ref['time'] = df_ref.index.strftime('%H:%M:%S')\n",
    "df_ref['timestamp'] = df_ref.index.strftime('%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "# Epoch format\n",
    "df_ref['epoch'] = df_ref.index.astype('int64')//1e9\n",
    "\n",
    "# Reset the Index of the DataFrame\n",
    "df_ref = df_ref.reset_index(drop=True)\n",
    "\n",
    "# Let's have a look to the resulting columns of the dataset\n",
    "df_ref.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the first rows of the **customized reference dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 3 rows in the dataframe\n",
    "df_ref.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our customized reference dataset of 1-minute irradiance measurements for 2020 and temporal data, we can start building the timeseries in different ways.\n",
    "\n",
    "### Time-series when timestamps are available:\n",
    "\n",
    "When timestamps are available, the most straightforward way to build the DataFrame with a datetime index is to convert the column with the timestamp into datetime format and set it as index.\n",
    "\n",
    "Let's see how!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dataframe copy of the reference dataset\n",
    "df = df_ref.copy()\n",
    "# Convert the timestamp string into datetime format \n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "# Set timestamp column as index\n",
    "df = df.set_index(df['timestamp'])\n",
    "# See the first 3 rows of the DataFrame with Datetime Index\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the timestamp is specified in the argument 'format' as a string and can be adapted to any case. The available options in Python can be checked in this [link](https://strftime.org/). \n",
    "\n",
    "Universal Time Coordinated (UTC) is usually the timestamp provided for many solar radiation data networks and platforms like the BSRN, PVGIS, etc. However, data can be also reported in local time like in our example. Timestamps can be converted to other timezones with the funcion *tz_convert*, which can be useful when dealing with data from different databases and locations worldwide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add UTC timestamp from the local time (Pacific Summer Time)\n",
    "df['timestamp_utc'] = df.index.tz_convert('UTC')\n",
    "# See the first 3 rows \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The valid timezone strings for other timezones can be found in this [link](https://pvlib-python.readthedocs.io/en/stable/timetimezones.html). When the timezone is not provided as part of the timestamp, the function *tz_localize* can be used to localize the values in a timezone-naive series. *tz_localize* will be used in the next example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series when date and time are available:\n",
    "\n",
    "When date and time are available in separate columns, a timestamp can be created in a new column and the new column can then be set as index and localized. Let's have a look how to do that:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dataframe copy of the reference dataset\n",
    "df = df_ref.copy()\n",
    "# New column with the date and time \n",
    "df['datetime'] = df['date'] + 'T' + df['time']\n",
    "# Convert the new column into datetime format \n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%dT%H:%M:%S')\n",
    "# Set the column 'datetime' as index and localize it to its timezone\n",
    "df = df.set_index(df['datetime']).tz_localize('Etc/GMT+8')\n",
    "# See the first 3 rows \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series when the time data is split in multiple columns:\n",
    "\n",
    "If time-related data are split across multiple columns, a timestamp can be created in a new column similarly than in the previous case. Let's imagine our dataset would have the year, month, day, hour, and minute in separate columns. In that case, we could build our time-series as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dataframe copy of the reference dataset\n",
    "df = df_ref.copy()\n",
    "# Let's reduce the code lines and define the new string within the 'to_datetime' function\n",
    "df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']], \n",
    "                                format = '%Y-%m-%d%H:%M')\n",
    "# Set the column 'datetime' as index\n",
    "df = df.set_index(df['datetime']) \n",
    "# Localize the datetime series\n",
    "df.index = df.index.tz_localize('Etc/GMT+8') \n",
    "# See the first 3 rows \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series when the timestamp is given as epoch (Unix Time)\n",
    "\n",
    "If the dataset has epoch timestamps, note that the data will have UTC time. However, it can be converted to any timezone using the function *tz_convert*. If there are epoch timestamps, a datetime series can be formed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dataframe copy of the reference dataset\n",
    "df = df_ref.copy()\n",
    "# Convert epoch timestamps to datetime format and localize\n",
    "df['datetime'] = pd.to_datetime(df['epoch'], unit='s', utc=True)\n",
    "# Set datetime as index and convert UTC time to local time\n",
    "df = df.set_index(df['datetime']).tz_convert('Etc/GMT+8')\n",
    "# See the results\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen how the same DataFrame with *datetimeindex* can be obtained in multiple ways depending on the format of time data provided.\n",
    "\n",
    "\n",
    "## Down and up-sampling time-series data<a id='timeseries_downup_sampling'></a>\n",
    "\n",
    "When assessing solar resource, you may need a different time-resolution than your data for a particular part of the analysis. In those cases, it is possible to **down-sample and up-sample the data at different temporal resolutions** using two different methods within [pandas library](https://pandas.pydata.org/) called *resample* and *asfreq*. Depending on your needs, you will opt for one or the other. Regardless of the method, both of them require a DataFrame with *datetimeindex* either time-aware (localized) or time-naive (not localized). \n",
    "\n",
    "### Method 'asfreq' vs. 'resample'\n",
    "Let's first create a new DataFrame with only the columns with solar data and see the differences between both methods with examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DataFrame with 1-minute data and solar data\n",
    "df_1min = df[['ghi', 'dhi', 'dni']]\n",
    "# See our new DataFrame\n",
    "df_1min.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to obtain a DataFrame down-sampled with the maximum monthly data with both methods and see the differences. With *asfreq*, it would be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min.asfreq(\"1M\").max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With *resample* the result would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min.resample(\"1M\").max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that the outputs are not the same and that is because the methods work differently. *asfreq* takes the value at the simultaneous stamps given by the frequency argument. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min.asfreq(\"1M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then *.max()* has returned the maximum of each of the columns. \n",
    "\n",
    "In contrast, *resample* does return the maximum value within the period of time at the specified frequency. *resample* method requires a mathematical operation to perform in the resampled data (the maximum value in our case). Otherwise, it would return a *DatetimeIndexResampler* object without showing any data. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min.resample(\"1M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *resample* method accepts multiple **mathematical and statistical operations**. For example: maximum (max), minimum (min), arithmetic mean (mean), standard deviation (std), median (median), mode (mode), addition (sum), among others. \n",
    "\n",
    "Both methods allow for multiple **frequencies options**, the available frequency tags within Python can be found [here](https://stackoverflow.com/questions/35339139/where-is-the-documentation-on-pandas-freq-tags)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sampling the data in a time-series\n",
    "\n",
    "Down-sampling permits turning more frequent values into less frequent. In the context of solar resource and considering our 1-minute resolution dataset, down-sampling can be used for:\n",
    "- Producing a timeseries of hourly/daily average irradiance.\n",
    "- Producing a timeseries of maximum daily irradiance.\n",
    "- Estimating the hourly/daily/monthly sums of irradiation.\n",
    "- And many more!\n",
    "\n",
    "Let's implement some of these listed examples!\n",
    "\n",
    "#### Producing hourly average irradiance from minutely observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to hourly mean values\n",
    "df_hourly = df_1min.resample(\"1H\").mean()\n",
    "# Showing the shape of the new DataFrame\n",
    "df_hourly.shape # returns Rows, Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8760 hours in a year. Yet, we can have a look to the first few rows of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time-series with the maximum irradiance would be similar replacing *'mean()'* with *'max()'*.\n",
    "\n",
    "#### Producing time-series of monthly total GHI, DHI, DNI irradiation from minutely observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to monthly aggregated values\n",
    "monthly_energy = df_1min[['ghi', 'dhi', 'dni']].resample(\"1M\").sum()*(1/60)\n",
    "# See the results expressed in kWh·sqm\n",
    "monthly_energy/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be done in similar way for other resolutions (e.g. daily or annual irradiation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-sampling the data in a time-series\n",
    "\n",
    "Up-sampling permits obtaining more frequent values from less frequent. For solar data, depending on the application up to sub-minutely data could be required and up-sampling is a technique that provides a manner to increase the temporal resolution to adapt it to our needs. For example, turning an hourly time-series into a half-hourly. Let's see an example using both *resample* and *asfreq*.\n",
    "\n",
    "#### Producing half-hourly irradiance series from hourly observations\n",
    "Using the DataFrame *df_hourly* created previously, it can be up-sample as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'resample' method:\n",
    "df_hourly.resample(\"30Min\").mean().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'asfreq' method:\n",
    "df_hourly.asfreq(\"30Min\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to the case of down-sampling, both *asfreq* and *resample* provide similar results when up-sampling. However, *asfreq* provides additional functionalities to treat the new timestamps without data, i.e. NaN values.\n",
    "\n",
    "By passing the argument *'method'* with the string *'backfill'* or *'bfill'* uses the next valid observation to fill the NaN value (back filling). If instead, the string *'pad'* or *'ffill'* is given, the method assigns the last valid observation forward to the next valid (forward filling). \n",
    "\n",
    "Let's see the same example adding this argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-hourly up-sample with back filling function\n",
    "df_hourly.asfreq(\"30Min\", method='bfill').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the DataFrame now contains the next valid hourly value in the newly obtained half-hourly timestamps of the previous hour. It would take the previous valid hourly value if we used forward filling. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-hourly up-sample with forward-filling function\n",
    "df_hourly.asfreq(\"30Min\", method='ffill').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward filling option provides the same value for o'clock and half past timestamps within the same hour. In addition to these two ways to complete the NaN values, the method *asfreq* can replace the NaN values with a constant. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-hourly up-sample filling the new timestamps with a constant\n",
    "df_hourly.asfreq(\"30Min\", fill_value=0).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the methods *asfreq* or *resample* will depend on your dataset and the analysis you aim to undertake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating time-series data<a id='timeseries_interpolation'></a>\n",
    "\n",
    "When up-sampling the data series, it can happen that back-filling, forward-filling and constant replacement does not necessarily work for your analysis/application. An alternative approach is interpolating the replacing the NaN values with an interpolated result. Interpolation in Pandas DataFrames with *DatetimeIndex* is done with the *interpolate* method.\n",
    "\n",
    "The mathematical interpolation method in *interpolate* is defined with the argument called *'method'*. Pandas permits several interpolation methods, such as 'linear', 'cubic', 'quadratic', 'spline', 'polynomial' and others. All the interpolation options can be found in the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html) of the *interpolate* method. \n",
    "\n",
    "Following the previous example, let's implement interpolation in the missing values of the half-hourly timestamps using 'linear', 'cubic' and 'polynomial' methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up-sample using the 'asfreq' method\n",
    "df_30min = df_hourly.asfreq(\"30Min\")\n",
    "# Interpolate missing values (NaN) with linear interpolation\n",
    "df_linear = df_30min.interpolate(method='linear')\n",
    "# See the results:\n",
    "df_linear.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, it can be implemented to other methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate missing values (NaN) with cubic interpolation\n",
    "df_cubic = df_30min.interpolate(method='cubic')\n",
    "# See the results:\n",
    "df_cubic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With polynomial interpolation, the degree or order of the polynomial function needs to be defined as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate missing values (NaN) with polynomial interpolation\n",
    "df_polynomial = df_30min.interpolate(method='polynomial', order=5)\n",
    "# See the results:\n",
    "df_polynomial.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpolation of NaN values when up-sampling time-series data can help overcome the issues of using back or forward filling, specially if you aim to up-sample at higher frequencies than the example shown (e.g. 1-hour to 15-minute resolution series). The mathematical methods available for interpolation within Pandas are diverse and cover beyond the most common interpolation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing time-series data<a id='timeseries_visualization'></a>\n",
    "\n",
    "It is often useful to visualize the data to grasp insighs and observe trends about the data. This section shows few examples to visualize time-series data.\n",
    "\n",
    "### Plotting a time-series for a day of interest\n",
    "\n",
    "Below there is an example to visualize a single day of interest. With DataFrames using *DatetimeIndex* it is easy to select a particular day and Pandas interacts with Matplotlib.Pyplot library to plot straight-away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting GHI for a given day in the time-series\n",
    "df_1min['2020-06-01']['ghi'].plot(label='GHI')\n",
    "plt.ylabel('Irradiance [W/m$^2$]')\n",
    "plt.xlabel('Local Time [HH:MM]')\n",
    "plt.legend(loc='best')\n",
    "plt.show() # Not needed in Jupyter Notebooks but usually required in other IDEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the effect of using average (*resample*) vs. instantaneous (*asfreq*) measurements when down-sampling our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting GHI for a given day in the time-series\n",
    "df_1min['2020-06-01']['ghi'].plot(label='1-min data', alpha=0.4) # Reference data\n",
    "df_1min.asfreq('30Min')['2020-06-01']['ghi'].plot(label='30-min instant.') # Instantaneous 30-min values\n",
    "df_1min.resample('30Min').mean()['2020-06-01']['ghi'].plot(label='30-min average') # Average 30-min values\n",
    "plt.title('Average vs. Actual GHI Measurements') # title of the figure\n",
    "plt.ylabel('Irradiance [W/m$^2$]') # y-axis label\n",
    "plt.xlabel('Local Time [HH:MM]') # x-axis label\n",
    "plt.legend(loc='upper left') # insert legend\n",
    "plt.show() # Not needed in Jupyter Notebook but usually required in other IDEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a time-series for a few consecutive days of interest\n",
    "\n",
    "Below there is an example to visualize a few consecutive days (e.g. 5 days) of interest. By using ['start date']:['end date'] it is possible to select time ranges easily with a DataFrame having a *DatetimeIndex*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to plot\n",
    "vars = ['ghi', 'dni', 'dhi'] \n",
    "# Create 3 subplots, with shared X and Y axis\n",
    "fig, axs = plt.subplots(3, sharex=True, sharey=True, figsize=(9,6))\n",
    "# Add title to the plot\n",
    "fig.suptitle('Average Hourly Solar Radiation Observations', fontsize=14)\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].plot(df_1min.resample('1H').mean()['2020-06-01':'2020-06-05'][vars[i]], label='Average') # Average hourly\n",
    "    axs[i].plot(df_1min.resample('1H').max()['2020-06-01':'2020-06-05'][vars[i]], label='Maximum') # Max. hourly\n",
    "    axs[i].plot(df_1min.resample('1H').min()['2020-06-01':'2020-06-05'][vars[i]], label='Minimum') # Min. hourly\n",
    "    axs[i].set_title(vars[i].upper()) # Title for each subplot\n",
    "fig.subplots_adjust(hspace=0.3) # Adjust the white space between the subplots titles\n",
    "fig.text(0.04, 0.5, 'Irradiance [W/m$^2$]', va='center', rotation='vertical', fontsize=12) # Common Y Axis\n",
    "fig.text(0.51, 0.04, 'Local Time', ha='center', fontsize=12) # Common X Axis\n",
    "plt.legend(loc='upper center', ncol=3) # Legend for the last subplot or 'axs[i].legend()' in the loop to a legend to each.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a time-series for a few non-consecutive days of interest\n",
    "\n",
    "Below there is an example to visualize a few non-consecutive days of interest, which could be the case when we would like to observe several days scattered throughout the year a single plot. In order to do this, we need to select the day of interest from the DataFrame and then reset its *DatetimeIndex*. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of days of interest\n",
    "days = ['2020-01-01', '2020-03-01', '2020-06-01', '2020-09-01']\n",
    "# Iterate over the days and plot each of them\n",
    "for day in days: \n",
    "    df_day = df_1min.resample('1H').mean()[day]['ghi'].to_frame()  # average hourly of GHI for current day\n",
    "    df_day = df_day.reset_index(drop=True) # reset its Index to numeric (i.e. 0,1,2,3...)\n",
    "    plt.plot(df_day, label=day) # plot the current day\n",
    "plt.title('Average Hourly GHI Measurements for Days of Interest') # title of the figure\n",
    "plt.xticks(np.arange(0, 25, step=3), np.arange(0, 25, step=3)) # set labels positions and names\n",
    "plt.ylabel('Irradiance [W/m$^2$]') # y-axis label\n",
    "plt.xlabel('Local Time') # x-axis label\n",
    "plt.legend(loc='best') # insert legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily insolation throughout the year\n",
    "\n",
    "With time-series data, the hourly/daily/monthly insolation (i.e. the sum of accumulated energy) can also be analysed throughout the year with time-series data. For example, below an example to visualize the daily insolation is shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily insolation expressed in kWh·sqm from GHI measurements\n",
    "daily_energy = (df_1min['ghi'].resample(\"1D\").sum()*(1/60))/1000 # selecting only GHI returns a Pandas Series\n",
    "\n",
    "# Create time-series plot\n",
    "daily_energy.plot(figsize=(9,6), legend=False) # plot timeseries \n",
    "plt.title('Time-series of Daily Insolation')  # add title\n",
    "plt.ylabel('Energy [kWh/m$^2$]') # add Y-axis label\n",
    "plt.xlabel('Time') # add X-axis label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-series data can also be visualized in other ways, for instance, as a heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for heat map of hourly insolation\n",
    "energy_array = pd.DataFrame() # empty DataFrame for the results\n",
    "for i in range(1,13): # iterate over months\n",
    "    # select the data in the month and eliminate the datetimeindex\n",
    "    df_month = daily_energy[daily_energy.index.month==i].reset_index(drop=True) \n",
    "    # rename the column with the number of the month\n",
    "    df_month.columns = [str(i)]\n",
    "    # Append results to the DataFrame\n",
    "    energy_array = pd.concat([energy_array, df_month], axis=1)\n",
    "# Transpose to have months in y-axis and days in x-axis\n",
    "energy_array = energy_array.transpose()\n",
    "# Rename the columns of the days \n",
    "energy_array.columns = np.arange(1, 32)\n",
    "\n",
    "# Plot heat map of daily insolation\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', # month labels\n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.heatmap(energy_array, cmap='CMRmap', linewidths=0.2, # plot heatmap with Seaborn (sns) library \n",
    "                xticklabels=2, annot=False,\n",
    "                cbar_kws={'label': 'Daily Energy [kWh/m$^2$]'})\n",
    "ax.set_title('Heat Map of Daily Insolation') # add title\n",
    "ax.set_yticklabels(months,rotation=0) # add the months as tick-labels for the y-axis\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0) # add the days as tick-labels for the x-axis\n",
    "ax.set_xlabel('Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section summary\n",
    "\n",
    "This section has shown how to build and work with a time-series in Python with multiple examples:\n",
    "- We have seen how to prepare a DataFrame with *DatatimeIndex* to be used as a time-series when the timestamps are given in multiple formats in the temporal data and local/UTC time. \n",
    "- Changes in the temporal resolution of the data can be applied by down and up-sampling the data and the differences between 2 available methods (*asfreq* and *resample*) have been shown with examples and different sampling frequencies. \n",
    "- The interpolation of missing data in time-series can be used to up-sample the resolution of the data and examples with some methods have been shown.\n",
    "- Finally, several ideas to visualize data have been presented. \n",
    "\n",
    "Overall, the possibilities with time-series of solar resource are many. The most useful and suitable analysis and visualizations will be determined by the application and scope of the study.\n",
    "\n",
    "# References<a id='references'></a>\n",
    "\n",
    "Andreas, A.; Stoffel, T.; (2006). University of Nevada (UNLV):\n",
    "Las Vegas, Nevada (Data); NREL Report No. DA-5500-56509.\n",
    "http://dx.doi.org/10.5439/1052548\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
